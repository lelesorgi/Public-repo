{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 Thomson-Reuters Tick History intraday data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import os\n",
    "\n",
    "import pdb\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "dask.config.set(scheduler=\"processes\")\n",
    "\n",
    "#@dask.delayed\n",
    "def load_TRTH_trade(filename,\n",
    "             tz_exchange=\"America/New_York\",\n",
    "             only_non_special_trades=True,\n",
    "             only_regular_trading_hours=True,\n",
    "             open_time=\"09:30:00\",\n",
    "             close_time=\"16:00:00\",\n",
    "             merge_sub_trades=True):\n",
    "    try:\n",
    "        if re.search('(csv|csv\\\\.gz)$',filename):\n",
    "            DF = pd.read_csv(filename)\n",
    "        if re.search(r'arrow$',filename):\n",
    "            DF = pd.read_arrow(filename)\n",
    "        if re.search('parquet$',filename):\n",
    "            DF = pd.read_parquet(filename)\n",
    "\n",
    "    except Exception as e:\n",
    "     #   print(\"load_TRTH_trade could not load \"+filename)\n",
    "     #   print(e)\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        DF.shape\n",
    "    except Exception as e: # DF does not exist\n",
    "        print(\"DF does not exist\")\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "    \n",
    "    if DF.shape[0]==0:\n",
    "        return None\n",
    "    \n",
    "    if only_non_special_trades:\n",
    "        DF = DF[DF[\"trade-stringflag\"]==\"uncategorized\"]\n",
    "\n",
    "    DF.drop(columns=[\"trade-rawflag\",\"trade-stringflag\"],axis=1,inplace=True)\n",
    "    \n",
    "    DF.index = pd.to_datetime(DF[\"xltime\"],unit=\"d\",origin=\"1899-12-30\",utc=True)\n",
    "    DF.index = DF.index.tz_convert(tz_exchange)  # .P stands for Arca, which is based at New York\n",
    "    DF.drop(columns=\"xltime\",inplace=True)\n",
    "    \n",
    "    if only_regular_trading_hours:\n",
    "        DF=DF.between_time(open_time,close_time)    # warning: ever heard e.g. about Thanksgivings?\n",
    "    \n",
    "    if merge_sub_trades:\n",
    "           DF=DF.groupby(DF.index).agg(trade_price=pd.NamedAgg(column='trade-price', aggfunc='mean'),\n",
    "                                       trade_volume=pd.NamedAgg(column='trade-volume', aggfunc='sum'))\n",
    "    \n",
    "    return DF\n",
    "\n",
    "\n",
    "\n",
    "#@dask.delayed\n",
    "def load_TRTH_bbo(filename,\n",
    "             tz_exchange=\"America/New_York\",\n",
    "             only_regular_trading_hours=True,\n",
    "             merge_sub_trades=True):\n",
    "    try:\n",
    "        if re.search(r'(csv|csv\\.gz)$',filename):\n",
    "            DF = pd.read_csv(filename)\n",
    "        if re.search(r'arrow$',filename):\n",
    "            DF = pd.read_arrow(filename)\n",
    "        if re.search(r'parquet$',filename):\n",
    "            DF = pd.read_parquet(filename) \n",
    "    except Exception as e:\n",
    "       # print(\"load_TRTH_bbo could not load \"+filename)\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        DF.shape\n",
    "    except Exception as e: # DF does not exist\n",
    "        print(\"DF does not exist\")\n",
    "        print(e)\n",
    "        return None\n",
    "\n",
    "    if DF.shape[0]==0:\n",
    "        return None\n",
    "    \n",
    "        \n",
    "    DF.index = pd.to_datetime(DF[\"xltime\"],unit=\"d\",origin=\"1899-12-30\",utc=True)\n",
    "    DF.index = DF.index.tz_convert(tz_exchange)  # .P stands for Arca, which is based at New York\n",
    "    DF.drop(columns=\"xltime\",inplace=True)\n",
    "    \n",
    "    if only_regular_trading_hours:\n",
    "        DF=DF.between_time(\"09:30:00\",\"16:00:00\")    # ever heard about Thanksgivings?\n",
    "        \n",
    "    if merge_sub_trades:\n",
    "        DF=DF.groupby(DF.index).last()\n",
    "    \n",
    "\n",
    "        \n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vaex\n",
    "\n",
    "@dask.delayed\n",
    "def load_merge_trade_bbo(ticker,date,\n",
    "                         country=\"US\",\n",
    "                         dirBase=\"data/raw/TRTH/equities/\",\n",
    "                         suffix=\"parquet\",\n",
    "                         suffix_save=None,\n",
    "                         dirSaveBase=\"data/clean/TRTH/equities/events\",\n",
    "                         saveOnly=False,\n",
    "                         doSave=False\n",
    "                        ):\n",
    "    \n",
    "    file_trade=dirBase+\"/\"+country+\"/trade/\"+ticker+\"/\"+str(date.date())+\"-\"+ticker+\"-trade.\"+suffix\n",
    "    file_bbo=file_trade.replace(\"trade\",\"bbo\")\n",
    "    trades=load_TRTH_trade(file_trade)\n",
    "    bbos  =load_TRTH_bbo(file_bbo)\n",
    "    try:\n",
    "        trades.shape + bbos.shape\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    events=trades.join(bbos,how=\"outer\")\n",
    "    \n",
    "    if doSave:\n",
    "        dirSave=dirSaveBase+\"/\"+country+\"/events/\"+ticker\n",
    "        if not os.path.isdir(dirSave):\n",
    "            os.makedirs(dirSave)\n",
    "\n",
    "        if suffix_save:\n",
    "            suffix=suffix_save\n",
    "        \n",
    "        file_events=dirSave+\"/\"+str(date.date())+\"-\"+ticker+\"-events\"+\".\"+suffix\n",
    "       # pdb.set_trace()\n",
    "\n",
    "        saved=False\n",
    "        if suffix==\"arrow\":\n",
    "            events=vaex.from_pandas(events,copy_index=True)\n",
    "            events.export_arrow(file_events)\n",
    "            saved=True\n",
    "        if suffix==\"parquet\":\n",
    "         #   pdb.set_trace()\n",
    "            events.to_parquet(file_events,use_deprecated_int96_timestamps=True)\n",
    "            saved=True\n",
    "            \n",
    "        if not saved:\n",
    "            print(\"suffix \"+suffix+\" : format not recognized\")\n",
    "            \n",
    "        if saveOnly:\n",
    "            return saved\n",
    "    return events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "ticker=\"SPY.P\"\n",
    "\n",
    "startDate=\"2010-01-01\"\n",
    "endDate=\"2010-12-31\"\n",
    "\n",
    "datelist = pd.date_range(startDate,endDate).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 37.5 ms, sys: 172 µs, total: 37.7 ms\n",
      "Wall time: 35.6 ms\n"
     ]
    }
   ],
   "source": [
    "%time allpromises=[load_merge_trade_bbo(\"SPY.P\",date,saveOnly=True,doSave=True,suffix=\"parquet\",suffix_save=\"arrow\") for date in datelist]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, it takes almost no time at all to create execution promises. Let us check that we really have promises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Delayed('load_merge_trade_bbo-f59696f4-2848-4bba-bc5e-d67409e26de9')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allpromises[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually perform a computation, simply call the compute() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.96 ms, sys: 300 µs, total: 10.3 ms\n",
      "Wall time: 2.44 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "allpromises[0].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us load all the files in a parallel way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.86 s, sys: 8.74 ms, total: 1.87 s\n",
      "Wall time: 52.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "alldata=dask.compute(allpromises) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Delayed, other ways\n",
    "\n",
    "\n",
    "There are alternative ways to delay a function: use dask.delayed(some_function) directly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "allpromises=[dask.delayed(pd.read_csv)(fn) for fn in allfiles]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or defined a delayed version of a function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_TRTH_trade_delayed=dask.delayed(load_TRTH_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del alldata  # cleanup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "### Merge trades and bbo data\n",
    "\n",
    "If one wishes to create a single dataframe, then one can proceeed in the following way. Note that it is not needed if one uses VAEX that can aggregate several files in a single virtual dataframe (see week 8)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_files=glob.glob(\"data/raw/TRTH/equities/US/trade/SPY.P/2009*\")\n",
    "trade_files.sort()\n",
    "\n",
    "allpromises=[load_TRTH_trade(fn) for fn in trade_files]\n",
    "trades=dask.compute(allpromises)[0]\n",
    "\n",
    "trades=pd.concat(trades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbo_files=glob.glob(\"data/raw/TRTH/equities/US/bbo/SPY.P/2009*\")\n",
    "bbo_files.sort()\n",
    "\n",
    "allpromises=[load_TRTH_bbo(fn) for fn in bbo_files]\n",
    "bbos=dask.compute(allpromises)[0]\n",
    "\n",
    "bbos=pd.concat(bbos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time events=trades.join(bbos,how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89048311, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are entering into the realms of big data. Let us save this object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before saving a parquet object, we need to ensure that the columns are in numeric format\n",
    "events[\"bid-price\"]=events[\"bid-price\"].values.astype(\"float\")\n",
    "events[\"bid-volume\"]=events[\"bid-volume\"].values.astype(\"float\")\n",
    "events[\"ask-price\"]=events[\"ask-price\"].values.astype(\"float\")\n",
    "events[\"ask-volume\"]=events[\"ask-volume\"].values.astype(\"float\")\n",
    "\n",
    "#so far, one still needs to add the use_deprectated_int96_timestamps option\n",
    "events.to_arrow(\"SPY_2009_events.\",use_deprecated_int96_timestamps=True,compression=\"brotli\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAEX to the rescue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    if events.shape:\n",
    "        del events\n",
    "except:\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead>\n",
       "<tr><th>#                                      </th><th>trade_price  </th><th>trade_volume  </th><th>bid-price  </th><th>bid-volume  </th><th>ask-price  </th><th>ask-volume  </th><th>index                        </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td><i style='opacity: 0.6'>0</i>          </td><td>nan          </td><td>nan           </td><td>90.44      </td><td>89          </td><td>90.46      </td><td>64          </td><td>2009-01-02 14:30:00.117999872</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>1</i>          </td><td>nan          </td><td>nan           </td><td>90.44      </td><td>84          </td><td>90.46      </td><td>72          </td><td>2009-01-02 14:30:00.117999872</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>2</i>          </td><td>nan          </td><td>nan           </td><td>90.44      </td><td>84          </td><td>90.45      </td><td>5           </td><td>2009-01-02 14:30:00.127999744</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>3</i>          </td><td>nan          </td><td>nan           </td><td>90.44      </td><td>76          </td><td>90.45      </td><td>5           </td><td>2009-01-02 14:30:00.127999744</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>4</i>          </td><td>nan          </td><td>nan           </td><td>90.44      </td><td>40          </td><td>90.45      </td><td>10          </td><td>2009-01-02 14:30:00.127999744</td></tr>\n",
       "<tr><td>...                                    </td><td>...          </td><td>...           </td><td>...        </td><td>...         </td><td>...        </td><td>...         </td><td>...                          </td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>365,559,066</i></td><td>nan          </td><td>nan           </td><td>125.79     </td><td>680         </td><td>125.8      </td><td>32          </td><td>2010-12-31 20:59:59.978000128</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>365,559,067</i></td><td>nan          </td><td>nan           </td><td>125.79     </td><td>689         </td><td>125.8      </td><td>32          </td><td>2010-12-31 20:59:59.978000128</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>365,559,068</i></td><td>nan          </td><td>nan           </td><td>125.79     </td><td>698         </td><td>125.8      </td><td>32          </td><td>2010-12-31 20:59:59.989999616</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>365,559,069</i></td><td>nan          </td><td>nan           </td><td>125.79     </td><td>689         </td><td>125.8      </td><td>32          </td><td>2010-12-31 20:59:59.989999616</td></tr>\n",
       "<tr><td><i style='opacity: 0.6'>365,559,070</i></td><td>nan          </td><td>nan           </td><td>125.79     </td><td>698         </td><td>125.8      </td><td>32          </td><td>2010-12-31 20:59:59.989999616</td></tr>\n",
       "</tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "#            trade_price    trade_volume    bid-price    bid-volume    ask-price    ask-volume    index\n",
       "0            nan            nan             90.44        89            90.46        64            2009-01-02 14:30:00.117999872\n",
       "1            nan            nan             90.44        84            90.46        72            2009-01-02 14:30:00.117999872\n",
       "2            nan            nan             90.44        84            90.45        5             2009-01-02 14:30:00.127999744\n",
       "3            nan            nan             90.44        76            90.45        5             2009-01-02 14:30:00.127999744\n",
       "4            nan            nan             90.44        40            90.45        10            2009-01-02 14:30:00.127999744\n",
       "...          ...            ...             ...          ...           ...          ...           ...\n",
       "365,559,066  nan            nan             125.79       680           125.8        32            2010-12-31 20:59:59.978000128\n",
       "365,559,067  nan            nan             125.79       689           125.8        32            2010-12-31 20:59:59.978000128\n",
       "365,559,068  nan            nan             125.79       698           125.8        32            2010-12-31 20:59:59.989999616\n",
       "365,559,069  nan            nan             125.79       689           125.8        32            2010-12-31 20:59:59.989999616\n",
       "365,559,070  nan            nan             125.79       698           125.8        32            2010-12-31 20:59:59.989999616"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import vaex\n",
    "\n",
    "df=vaex.open(\"data/clean/TRTH/equities/events/US/events/SPY.P/2010*arrow\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.export(\"SPY_2009-2010_events.arrow\",compression=\"brotli\")   # 20Gb uncompressed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
